#### Введение в Big O Notation

Big O Notation (или "О-большое") — это математическая нотация, которая используется для описания производительности алгоритмов. Она помогает нам понять, как быстро растет время выполнения алгоритма или объем используемой памяти в зависимости от размера входных данных. 

Основная идея Big O заключается в том, чтобы оценить **наихудший сценарий** работы алгоритма. Это позволяет нам сравнивать эффективность разных алгоритмов и выбирать наиболее подходящий для решения конкретной задачи.
#### Зачем нужно Big O Notation?

1. **Сравнение алгоритмов**: Big O позволяет сравнивать алгоритмы по их эффективности. Например, если у нас есть два алгоритма, которые решают одну и ту же задачу, мы можем использовать Big O, чтобы определить, какой из них будет работать быстрее на больших объемах данных.

2. **Прогнозирование производительности**: Зная Big O алгоритма, мы можем предсказать, как он будет работать при увеличении объема данных. Это особенно важно при работе с большими данными, где даже небольшие улучшения в производительности могут иметь значительный эффект.

3. **Оптимизация кода**: Понимание Big O помогает находить узкие места в коде и оптимизировать их. Например, если мы видим, что какой-то алгоритм имеет сложность O(n²), мы можем попытаться заменить его на алгоритм с меньшей сложностью, например O(n log n).

#### Основные понятия Big O

Big O описывает верхнюю границу времени выполнения алгоритма. Это означает, что мы рассматриваем наихудший случай, когда алгоритм работает дольше всего. Например, если алгоритм имеет сложность O(n), это означает, что время выполнения растет линейно с увеличением размера входных данных.

Основные виды сложности, которые мы будем рассматривать:

1. **O(1)** — константное время.
2. **O(log n)** — логарифмическое время.
3. **O(n)** — линейное время.
4. **O(n log n)** — линейно-логарифмическое время.
5. **O(n²)** — квадратичное время.
6. **O(2^n)** — экспоненциальное время.
7. **O(n!)** — факториальное время.

![[Pasted image 20250307085439.png]]

#### Пример 1: O(1) — Константное время

Алгоритм с константным временем выполнения всегда выполняется за одно и то же время, независимо от размера входных данных. Это самый эффективный вид алгоритмов.

Пример на Python:

```python
def get_first_element(arr):
    return arr[0]
```

В этом примере функция `get_first_element` всегда возвращает первый элемент массива. Независимо от того, сколько элементов в массиве (10, 1000 или 1 000 000), время выполнения будет одинаковым. Таким образом, сложность этого алгоритма — O(1).

#### Пример 2: O(n) — Линейное время

Алгоритм с линейным временем выполнения имеет сложность, которая растет пропорционально размеру входных данных. Если размер данных увеличивается в 10 раз, время выполнения также увеличится в 10 раз.

Пример на Python:

```python
def print_all_elements(arr):
    for element in arr:
        print(element)
```

В этом примере функция `print_all_elements` проходит по каждому элементу массива и выводит его на экран. Если массив содержит `n` элементов, то цикл выполнится `n` раз. Таким образом, сложность этого алгоритма — O(n).

#### Пример 3: O(n²) — Квадратичное время

Алгоритм с квадратичным временем выполнения имеет сложность, которая растет пропорционально квадрату размера входных данных. Это часто встречается в алгоритмах, которые используют вложенные циклы.

Пример на Python:

```python
def print_all_pairs(arr):
    for i in arr:
        for j in arr:
            print(i, j)
```

В этом примере функция `print_all_pairs` проходит по каждому элементу массива дважды (вложенные циклы). Если массив содержит `n` элементов, то общее количество итераций будет `n * n = n²`. Таким образом, сложность этого алгоритма — O(n²).


---
#### Пример 4: O(log n) — Логарифмическое время

Алгоритмы с логарифмической сложностью работают быстрее, чем линейные, потому что они уменьшают объем работы вдвое на каждом шаге. Логарифмическая сложность часто встречается в алгоритмах, которые используют стратегию "разделяй и властвуй", например, бинарный поиск.

**Пример на Python: Бинарный поиск**

Бинарный поиск работает только на отсортированных массивах. Он делит массив пополам на каждом шаге, отбрасывая половину элементов, которые не могут содержать искомое значение.

```python
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1  # Элемент не найден
```

**Как это работает:**
1. На каждом шаге массив делится пополам.
2. Если искомый элемент находится в середине, алгоритм завершается.
3. Если элемент меньше середины, поиск продолжается в левой половине.
4. Если элемент больше середины, поиск продолжается в правой половине.

**Сложность: O(log n)**
- Каждый шаг уменьшает размер задачи вдвое. Например, для массива из 16 элементов потребуется максимум 4 шага (log₂16 = 4).

---
#### Пример 5: O(n log n) — Линейно-логарифмическое время

Алгоритмы с такой сложностью часто встречаются в эффективных алгоритмах сортировки, таких как **сортировка слиянием (Merge Sort)** или **быстрая сортировка (Quick Sort)**. Они сочетают в себе линейный и логарифмический подходы.

**Пример на Python: Сортировка слиянием**

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    
    # Разделяем массив на две половины
    mid = len(arr) // 2
    left_half = merge_sort(arr[:mid])
    right_half = merge_sort(arr[mid:])
    
    # Сливаем две отсортированные половины
    return merge(left_half, right_half)

def merge(left, right):
    sorted_array = []
    i = j = 0
    
    # Сливаем два массива, сравнивая элементы
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            sorted_array.append(left[i])
            i += 1
        else:
            sorted_array.append(right[j])
            j += 1
    
    # Добавляем оставшиеся элементы
    sorted_array.extend(left[i:])
    sorted_array.extend(right[j:])
    return sorted_array
```

**Как это работает:**
1. Массив рекурсивно делится на две половины, пока не останутся массивы из одного элемента.
2. Затем эти массивы сливаются в отсортированном порядке.

**Сложность: O(n log n)**
- Разделение массива на половины занимает O(log n) шагов.
- На каждом уровне рекурсии выполняется слияние, которое занимает O(n) времени.
- Итоговая сложность: O(n log n).

---
#### Пример 6: O(2^n) — Экспоненциальное время

Алгоритмы с экспоненциальной сложностью очень медленные и используются только для небольших объемов данных. Такая сложность часто встречается в задачах, где требуется перебор всех возможных комбинаций, например, в рекурсивных алгоритмах.

**Пример на Python: Числа Фибоначчи (наивная реализация)**

```python
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n - 1) + fibonacci(n - 2)
```

**Как это работает:**
1. Каждый вызов функции `fibonacci` вызывает два дополнительных вызова.
2. Количество вызовов растет экспоненциально с увеличением `n`.

**Сложность: O(2^n)**
- Например, для `n = 5` выполняется 15 вызовов, а для `n = 10` — уже 177 вызовов.

---
#### Пример 7: O(n!) — Факториальное время

Алгоритмы с факториальной сложностью являются самыми медленными. Они используются в задачах, где требуется перебор всех возможных перестановок или комбинаций.

**Пример на Python: Генерация всех перестановок**

```python
from itertools import permutations

def generate_permutations(arr):
    return list(permutations(arr))
```

**Как это работает:**
1. Функция `permutations` из модуля `itertools` генерирует все возможные перестановки массива.
2. Количество перестановок для массива из `n` элементов равно `n!`.

**Сложность: O(n!)**
- Например, для массива из 5 элементов количество перестановок равно 120 (5! = 120), а для 10 элементов — уже 3 628 800.

---

Далее поговорим о **пространственной сложности** (использовании памяти) и о том, как она связана с временной сложностью. Также мы рассмотрим, как анализировать сложность алгоритмов, содержащих несколько операций, и разберем примеры.

#### Пространственная сложность (Space Complexity)

Пространственная сложность — это мера того, сколько дополнительной памяти использует алгоритм в зависимости от размера входных данных. Она также выражается с помощью Big O Notation. Пространственная сложность важна, потому что даже если алгоритм работает быстро, он может быть неэффективным, если использует слишком много памяти.

##### Пример 1: O(1) — Константная пространственная сложность

Алгоритм с константной пространственной сложностью использует фиксированное количество памяти, независимо от размера входных данных.

**Пример на Python:**

```python
def sum_of_two_numbers(a, b):
    return a + b
```

В этом примере функция `sum_of_two_numbers` использует только несколько переменных (`a`, `b` и результат), которые занимают фиксированное количество памяти. Таким образом, пространственная сложность — O(1).

##### Пример 2: O(n) — Линейная пространственная сложность

Алгоритм с линейной пространственной сложностью использует память, пропорциональную размеру входных данных.

**Пример на Python:**

```python
def create_array(n):
    return [i for i in range(n)]
```

В этом примере функция `create_array` создает массив из `n` элементов. Память, необходимая для хранения массива, растет линейно с увеличением `n`. Таким образом, пространственная сложность — O(n).

---
#### Анализ сложности алгоритмов с несколькими операциями

Часто алгоритмы состоят из нескольких операций, каждая из которых имеет свою временную сложность. В таких случаях важно понимать, как комбинировать эти сложности.

##### Правила комбинирования сложностей

1. **Сложение сложностей (O(f(n)) + O(g(n)) = O(f(n) + g(n)))**
   Если алгоритм выполняет несколько операций последовательно, его общая сложность равна сумме сложностей этих операций.

2. **Умножение сложностей (O(f(n)) * O(g(n)) = O(f(n) * g(n)))**
   Если одна операция выполняется внутри другой (например, вложенные циклы), их сложности перемножаются.

##### Пример 1: Сложение сложностей
Рассмотрим алгоритм, который сначала сортирует массив, а затем ищет в нем элемент.
```python
def sort_and_search(arr, target):
    arr.sort()  # Сложность: O(n log n)
    for element in arr:  # Сложность: O(n)
        if element == target:
            return True
    return False
```

- Сортировка массива занимает O(n log n).
- Поиск элемента занимает O(n).
- Общая сложность: O(n log n) + O(n) = O(n log n) (доминирует более сложная операция).

##### Пример 2: Умножение сложностей
Рассмотрим алгоритм, который перебирает все пары элементов в массиве.
```python
def print_all_pairs(arr):
    for i in arr:  # Сложность: O(n)
        for j in arr:  # Сложность: O(n)
            print(i, j)
```

- Внешний цикл выполняется O(n) раз.
- Внутренний цикл выполняется O(n) раз для каждой итерации внешнего цикла.
- Общая сложность: O(n) * O(n) = O(n²).

---

#### Пример 3: Сложность рекурсивных алгоритмов
Рекурсивные алгоритмы могут иметь сложность, которая зависит от глубины рекурсии и количества операций на каждом уровне рекурсии.

**Пример на Python: Числа Фибоначчи (оптимизированная версия)**
```python
def fibonacci(n, memo={}):
    if n in memo:
        return memo[n]
    if n <= 1:
        return n
    memo[n] = fibonacci(n - 1, memo) + fibonacci(n - 2, memo)
    return memo[n]
```

**Как это работает:**
1. Используется мемоизация (кэширование результатов), чтобы избежать повторных вычислений.
2. Каждое значение вычисляется только один раз.

**Сложность: O(n)**
- Глубина рекурсии — O(n).
- Каждый вызов функции выполняется за O(1) благодаря мемоизации.

---
#### Пример 4: Сложность алгоритмов с несколькими структурами данных
Иногда алгоритмы используют несколько структур данных, каждая из которых имеет свою сложность.

**Пример на Python: Поиск пересечения двух массивов**

```python
def find_intersection(arr1, arr2):
    set1 = set(arr1)  # Сложность: O(n)
    set2 = set(arr2)  # Сложность: O(m)
    return list(set1.intersection(set2))  # Сложность: O(min(n, m))
```

- Преобразование массивов в множества занимает O(n) и O(m) соответственно.
- Поиск пересечения множеств занимает O(min(n, m)).
- Общая сложность: O(n + m).

---
#### Практическое применение Big O Notation

##### 1. Выбор алгоритма в зависимости от задачи
При выборе алгоритма важно учитывать не только его временную сложность, но и особенности задачи. Например:

- **Для небольших данных** (например, массив из 10 элементов) даже алгоритм с O(n²) может работать достаточно быстро.
- **Для больших данных** (например, массив из 1 000 000 элементов) лучше использовать алгоритмы с O(n log n) или O(n).

**Пример: Сортировка массива**

- Если массив небольшой, можно использовать простую сортировку пузырьком (O(n²)).
- Если массив большой, лучше использовать быструю сортировку (O(n log n)).

##### 2. Оценка сложности реального кода
При анализе реального кода важно учитывать все операции, включая вызовы функций, циклы и работу со структурами данных.

**Пример:**
```python
def process_data(data):
    result = []
    for item in data:  # O(n)
        if item > 0:  # O(1)
            result.append(item * 2)  # O(1)
    result.sort()  # O(n log n)
    return result
```
- Цикл `for` выполняется O(n) раз.
- Операции внутри цикла занимают O(1).
- Сортировка массива занимает O(n log n).
- Общая сложность: O(n) + O(n log n) = O(n log n).

##### 3. Избежание распространенных ошибок
- **Игнорирование констант**: В Big O Notation константы игнорируются. Например, O(2n) упрощается до O(n).
- **Неправильный анализ вложенных циклов**: Важно учитывать, как циклы взаимодействуют друг с другом.
- **Забывание о пространственной сложности**: Даже если алгоритм работает быстро, он может использовать слишком много памяти.

**Пример ошибки:**
```python
def duplicate_elements(arr):
    result = []
    for i in arr:  # O(n)
        for j in arr:  # O(n)
            result.append(i + j)  # O(1)
    return result
```
- Вложенные циклы создают сложность O(n²).
- Если массив большой, это может привести к значительному увеличению времени выполнения.

---
#### Резюме и ключевые моменты

1. **Big O Notation** — это инструмент для оценки эффективности алгоритмов. Она описывает, как время выполнения или использование памяти растет с увеличением размера входных данных.

2. **Основные виды сложности**:
   - O(1): Константное время.
   - O(log n): Логарифмическое время.
   - O(n): Линейное время.
   - O(n log n): Линейно-логарифмическое время.
   - O(n²): Квадратичное время.
   - O(2^n): Экспоненциальное время.
   - O(n!): Факториальное время.

3. **Пространственная сложность** — это мера того, сколько памяти использует алгоритм. Она также выражается с помощью Big O.

4. **Правила анализа сложности**:
   - Сложение сложностей: O(f(n)) + O(g(n)) = O(f(n) + g(n)).
   - Умножение сложностей: O(f(n)) * O(g(n)) = O(f(n) * g(n)).

5. **Практические советы**:
   - Выбирайте алгоритмы в зависимости от размера данных.
   - Учитывайте как временную, так и пространственную сложность.
   - Избегайте вложенных циклов с высокой сложностью.

---

В этом примере мы рассмотрим различные способы вычисления суммы элементов и измерим время их выполнения. Мы будем использовать модуль `time` для замера времени и сравним производительность разных подходов.

#### Способы вычисления суммы:
1. **Цикл `for`**.
2. **Встроенная функция `sum()`**.
3. **Генератор списка**.
4. **Математическая формула суммы арифметической прогрессии**.
5. **Использование `numpy`**.
6. **Рекурсия**.
7. **Использование `reduce` из модуля `functools`**.
#### Код для замера времени
```python
import time
import numpy as np
from functools import reduce

# Функция для замера времени выполнения
def measure_time(func, *args):
    start_time = time.time()
    result = func(*args)
    end_time = time.time()
    return result, end_time - start_time

# 1. Сумма через цикл for
def sum_with_for_loop(arr):
    total = 0
    for num in arr:
        total += num
    return total

# 2. Сумма через встроенную функцию sum()
def sum_with_builtin(arr):
    return sum(arr)

# 3. Сумма через генератор списка
def sum_with_list_comprehension(arr):
    return sum([num for num in arr])

# 4. Сумма через математическую формулу (арифметическая прогрессия)
def sum_with_math_formula(n):
    return n * (n + 1) // 2

# 5. Сумма через numpy
def sum_with_numpy(arr):
    return np.sum(arr)

# 6. Сумма через рекурсию
def sum_with_recursion(arr):
    if not arr:
        return 0
    return arr[0] + sum_with_recursion(arr[1:])

# 7. Сумма через reduce
def sum_with_reduce(arr):
    return reduce(lambda x, y: x + y, arr)

# Создаем массив из n элементов
n = 1000000
arr = list(range(1, n + 1))

# Замер времени для каждого способа
result_for, time_for = measure_time(sum_with_for_loop, arr)
result_builtin, time_builtin = measure_time(sum_with_builtin, arr)
result_list_comp, time_list_comp = measure_time(sum_with_list_comprehension, arr)
result_math, time_math = measure_time(sum_with_math_formula, n)
result_numpy, time_numpy = measure_time(sum_with_numpy, np.array(arr))
result_recursion, time_recursion = measure_time(sum_with_recursion, arr[:1000])  # Ограничиваем для рекурсии
result_reduce, time_reduce = measure_time(sum_with_reduce, arr)

# Вывод результатов
print(f"Сумма через цикл for: {result_for}, время: {time_for:.6f} сек")
print(f"Сумма через встроенную функцию sum(): {result_builtin}, время: {time_builtin:.6f} сек")
print(f"Сумма через генератор списка: {result_list_comp}, время: {time_list_comp:.6f} сек")
print(f"Сумма через математическую формулу: {result_math}, время: {time_math:.6f} сек")
print(f"Сумма через numpy: {result_numpy}, время: {time_numpy:.6f} сек")
print(f"Сумма через рекурсию (n=1000): {result_recursion}, время: {time_recursion:.6f} сек")
print(f"Сумма через reduce: {result_reduce}, время: {time_reduce:.6f} сек")
```

---

#### Результаты выполнения
Пример вывода (зависит от вашего компьютера):
```
Сумма через цикл for: 500000500000, время: 0.050123 сек
Сумма через встроенную функцию sum(): 500000500000, время: 0.020456 сек
Сумма через генератор списка: 500000500000, время: 0.080789 сек
Сумма через математическую формулу: 500000500000, время: 0.000001 сек
Сумма через numpy: 500000500000, время: 0.001234 сек
Сумма через рекурсию (n=1000): 500500, время: 0.000345 сек
Сумма через reduce: 500000500000, время: 0.060123 сек
```

#### Выводы
- **Самый быстрый способ**: Использование математической формулы (если применимо) или встроенной функции `sum()`.
- **Самый универсальный способ**: Встроенная функция `sum()`.
- **Самый медленный способ**: Рекурсия и генератор списка (из-за накладных расходов).

Этот пример наглядно показывает, как выбор алгоритма влияет на производительность. Для задач, где важна скорость, всегда стоит выбирать наиболее эффективные подходы.

----

### Сортировки: от простых к сложным

Сортировка — это процесс упорядочивания элементов в определённом порядке (например, по возрастанию или убыванию). Существует множество алгоритмов сортировки, которые различаются по сложности, скорости и использованию памяти. В этом руководстве мы рассмотрим несколько популярных алгоритмов сортировки, начиная с самых простых и наглядных (например, пузырьковой сортировки) и заканчивая более сложными, но быстрыми (например, быстрой сортировкой и сортировкой слиянием).

---

### 1. Пузырьковая сортировка (Bubble Sort)

#### Описание:
Пузырьковая сортировка — это один из самых простых алгоритмов сортировки. Он проходит по списку несколько раз, сравнивая соседние элементы и меняя их местами, если они находятся в неправильном порядке. Процесс повторяется, пока список не будет отсортирован.
#### Временная сложность:
- В худшем случае: **O(n²)**
- В лучшем случае: **O(n)** (если список уже отсортирован)
- Средний случай: **O(n²)**
#### Пример на Python:
```python
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n - i - 1):
            if arr[j] > arr[j + 1]:
                arr[j], arr[j + 1] = arr[j + 1], arr[j]  # Меняем элементы местами

# Пример использования
arr = [64, 34, 25, 12, 22, 11, 90]
bubble_sort(arr)
print("Отсортированный массив:", arr)
# Вывод: Отсортированный массив: [11, 12, 22, 25, 34, 64, 90]
```

---
### 2. Сортировка выбором (Selection Sort)

#### Описание:
Сортировка выбором работает следующим образом: на каждом шаге алгоритм находит минимальный элемент из оставшейся части списка и меняет его местами с текущим элементом.

#### Временная сложность:
- В худшем случае: **O(n²)**
- В лучшем случае: **O(n²)**
- Средний случай: **O(n²)**

#### Пример на Python:
```python
def selection_sort(arr):
    n = len(arr)
    for i in range(n):
        min_idx = i
        for j in range(i + 1, n):
            if arr[j] < arr[min_idx]:
                min_idx = j
        arr[i], arr[min_idx] = arr[min_idx], arr[i]  # Меняем элементы местами

# Пример использования
arr = [64, 25, 12, 22, 11]
selection_sort(arr)
print("Отсортированный массив:", arr)
# Вывод: Отсортированный массив: [11, 12, 22, 25, 64]
```

---
### 3. Сортировка вставками (Insertion Sort)

#### Описание:
Сортировка вставками работает так: на каждом шаге алгоритм берёт один элемент и вставляет его в правильное место в уже отсортированной части списка.

#### Временная сложность:
- В худшем случае: **O(n²)**
- В лучшем случае: **O(n)** (если список уже отсортирован)
- Средний случай: **O(n²)**

#### Пример на Python:
```python
def insertion_sort(arr):
    for i in range(1, len(arr)):
        key = arr[i]
        j = i - 1
        while j >= 0 and key < arr[j]:
            arr[j + 1] = arr[j]
            j -= 1
        arr[j + 1] = key

# Пример использования
arr = [12, 11, 13, 5, 6]
insertion_sort(arr)
print("Отсортированный массив:", arr)
# Вывод: Отсортированный массив: [5, 6, 11, 12, 13]
```

---
### 4. Быстрая сортировка (Quick Sort)

#### Описание:
Быстрая сортировка использует стратегию "разделяй и властвуй". Алгоритм выбирает опорный элемент (pivot) и разделяет список на две части: элементы меньше опорного и элементы больше опорного. Затем рекурсивно сортирует обе части.

#### Временная сложность:
- В худшем случае: **O(n²)** (редко, если опорный элемент выбирается неудачно)
- В лучшем случае: **O(n log n)**
- Средний случай: **O(n log n)**

#### Пример на Python:
```python
def quick_sort(arr):
    if len(arr) <= 1:
        return arr
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    return quick_sort(left) + middle + quick_sort(right)

# Пример использования
arr = [64, 34, 25, 12, 22, 11, 90]
sorted_arr = quick_sort(arr)
print("Отсортированный массив:", sorted_arr)
# Вывод: Отсортированный массив: [11, 12, 22, 25, 34, 64, 90]
```

---
### 5. Сортировка слиянием (Merge Sort)

#### Описание:
Сортировка слиянием также использует стратегию "разделяй и властвуй". Алгоритм разделяет список на две половины, рекурсивно сортирует каждую половину, а затем объединяет (сливает) их в один отсортированный список.

#### Временная сложность:
- В худшем случае: **O(n log n)**
- В лучшем случае: **O(n log n)**
- Средний случай: **O(n log n)**

#### Пример на Python:
```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    return merge(left, right)

def merge(left, right):
    result = []
    i = j = 0
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    result.extend(left[i:])
    result.extend(right[j:])
    return result

# Пример использования
arr = [38, 27, 43, 3, 9, 82, 10]
sorted_arr = merge_sort(arr)
print("Отсортированный массив:", sorted_arr)
# Вывод: Отсортированный массив: [3, 9, 10, 27, 38, 43, 82]
```

---
### 6. Пирамидальная сортировка (Heap Sort)

#### Описание:
Пирамидальная сортировка использует структуру данных "куча" (heap). Алгоритм сначала строит кучу из списка, а затем извлекает элементы из кучи в отсортированном порядке.

#### Временная сложность:
- В худшем случае: **O(n log n)**
- В лучшем случае: **O(n log n)**
- Средний случай: **O(n log n)**

#### Пример на Python:
```python
def heapify(arr, n, i):
    largest = i
    left = 2 * i + 1
    right = 2 * i + 2

    if left < n and arr[left] > arr[largest]:
        largest = left

    if right < n and arr[right] > arr[largest]:
        largest = right

    if largest != i:
        arr[i], arr[largest] = arr[largest], arr[i]
        heapify(arr, n, largest)

def heap_sort(arr):
    n = len(arr)
    for i in range(n // 2 - 1, -1, -1):
        heapify(arr, n, i)
    for i in range(n - 1, 0, -1):
        arr[i], arr[0] = arr[0], arr[i]
        heapify(arr, i, 0)

# Пример использования
arr = [12, 11, 13, 5, 6, 7]
heap_sort(arr)
print("Отсортированный массив:", arr)
# Вывод: Отсортированный массив: [5, 6, 7, 11, 12, 13]
```

---
### Заключение
Мы рассмотрели несколько алгоритмов сортировки, начиная с простых (пузырьковая, выбором, вставками) и заканчивая более сложными, но быстрыми (быстрая сортировка, сортировка слиянием, пирамидальная сортировка). 

- **Для больших данных** лучше использовать быстрые алгоритмы, такие как быстрая сортировка или сортировка слиянием.

